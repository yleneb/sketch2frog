{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from IPython import get_ipython\r\n",
    "get_ipython().run_line_magic('reload_ext', 'autoreload')\r\n",
    "get_ipython().run_line_magic('autoreload', '2')\r\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import matplotlib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "import tensorflow_addons as tfa\r\n",
    "import numpy as np\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import albumentations as A\r\n",
    "from scipy.signal import convolve2d\r\n",
    "from src.config import PATH, DATA_DIR, MODELS_DIR"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "IMAGE_SHAPE = [256,256]\r\n",
    "EXAMPLES_DIR = DATA_DIR / 'examples'\r\n",
    "MODEL_PATH = MODELS_DIR / '2021-10-06 1343' / '200E'\r\n",
    "# MODEL_PATH = MODELS_DIR / '2021-10-05 1618' / '200E'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# we only want the generator\r\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\r\n",
    "model = model.generator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def decode_sketch(sketch_path, image_shape, resize_method):\r\n",
    "    # takes a png file path and returns a tensor\r\n",
    "    sketch = tf.io.read_file(sketch_path)\r\n",
    "    sketch = tf.io.decode_png(sketch)\r\n",
    "    sketch = tf.cast(sketch, tf.float32) / 255\r\n",
    "    sketch = tf.image.resize(sketch, image_shape, method=resize_method)\r\n",
    "    return sketch\r\n",
    "\r\n",
    "def thicken_sketch(sketch, filter_size=3):\r\n",
    "    # what background=0, lines=1\r\n",
    "    sketch = 1-sketch\r\n",
    "    \r\n",
    "    print('thickening')\r\n",
    "    \r\n",
    "    # perform convolution\r\n",
    "    conv_filter = np.ones([filter_size,filter_size])\r\n",
    "    conv_image = convolve2d(sketch, conv_filter, mode='same')\r\n",
    "    \r\n",
    "    # convert back to binary\r\n",
    "    conv_image[conv_image <  0.9] = 0\r\n",
    "    conv_image[conv_image >= 0.9] = 1\r\n",
    "    \r\n",
    "    # reset background to 1\r\n",
    "    conv_image = 1-conv_image\r\n",
    "    return conv_image\r\n",
    "\r\n",
    "def data_augmentation(image, image_size):    \r\n",
    "    # Instantiate augmentations - jitter, rotate, mirror\r\n",
    "    transforms = A.Compose([\r\n",
    "        A.PadIfNeeded(min_height=image_size[0]+20, min_width=image_size[1]+20, border_mode=cv2.BORDER_CONSTANT, value=[1,1,1]),\r\n",
    "        A.Rotate(limit=40, border_mode=cv2.BORDER_CONSTANT, value=[1,1,1]),\r\n",
    "        A.RandomCrop(*image_size),\r\n",
    "        A.HorizontalFlip()])\r\n",
    "    \r\n",
    "    data = {\"image\":image}\r\n",
    "    aug_data = transforms(**data)\r\n",
    "    aug_image = aug_data[\"image\"]\r\n",
    "    \r\n",
    "    return aug_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def show_prediction(img, pred, size):\r\n",
    "    \"\"\"Take the sketch and prediction and plot alongside\"\"\"\r\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(size*2, size*1))\r\n",
    "\r\n",
    "    axs[0].imshow(img.numpy(), cmap='gray')\r\n",
    "    axs[1].imshow((pred.numpy().squeeze()+1)/2)\r\n",
    "\r\n",
    "    # remove axis ticks\r\n",
    "    for ax in matplotlib.cbook.flatten(axs):\r\n",
    "        ax.set(xticks=[], yticks=[])\r\n",
    "\r\n",
    "    # set titles\r\n",
    "    axs[0].set_title('Sketch')\r\n",
    "    axs[1].set_title('Prediction')\r\n",
    "\r\n",
    "    # adjust styling and show\r\n",
    "    fig.patch.set_facecolor('white')     \r\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\r\n",
    "    plt.show()\r\n",
    "    plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def predict_and_show(model, filepath, image_shape=[128,128], size=3, resize_method='area', threshold=0.9, thicken=0, aug=False, save=False, show=True):\r\n",
    "    \"\"\"Resizing with method=area does much much better on the MSPaint examples\"\"\"\r\n",
    "    \r\n",
    "    # load file and make prediction\r\n",
    "    sketch = decode_sketch(str(filepath), image_shape, resize_method)\r\n",
    "    \r\n",
    "    # hand drawn sketches need extra preprocessing\r\n",
    "    if sketch.shape[-1]==3:\r\n",
    "        sketch = tf.image.rgb_to_grayscale(sketch)\r\n",
    "        sketch = sketch.numpy()[:,:,0]\r\n",
    "        sketch[sketch <  threshold] = 0\r\n",
    "        sketch[sketch >= threshold] = 1\r\n",
    "        if thicken:\r\n",
    "            sketch = thicken_sketch(sketch, filter_size=thicken)\r\n",
    "        if aug:\r\n",
    "            sketch = data_augmentation(sketch[:,:,np.newaxis], image_shape)\r\n",
    "        sketch = tf.constant(sketch)\r\n",
    "    \r\n",
    "    # predict and plot\r\n",
    "    image = model(sketch[tf.newaxis, ...])\r\n",
    "    if save:\r\n",
    "        img = (image.numpy().squeeze()+1)/2\r\n",
    "        img = (img*256).astype(np.uint8)\r\n",
    "        img = Image.fromarray(img)\r\n",
    "        img.save(save)\r\n",
    "    if show:\r\n",
    "        show_prediction(sketch, image, size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# for layer in model.layers:\r\n",
    "#     if 'dropout' in layer.name:\r\n",
    "#         layer.rate = 0.5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "for i in range(20):\r\n",
    "    for filepath in EXAMPLES_DIR.glob('For Report/*.png'): # 'frog-sketch-[0-9].png' '*[.png|.jpg]'\r\n",
    "        save_dir = EXAMPLES_DIR / 'For Report' / 'Preds - large'\r\n",
    "        fname = filepath.name[:-4] + f'-{i:02d}' + filepath.suffix\r\n",
    "        predict_and_show(model, filepath, image_shape=IMAGE_SHAPE, thicken=0, size=10, aug=True, save=save_dir/fname, show=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is sensitive to line width."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('sketch2frog': conda)"
  },
  "interpreter": {
   "hash": "cf271db479be4d4c6e21fd422531edba34ffb0b5173e4ffd91deb4fcee9a4d1e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}